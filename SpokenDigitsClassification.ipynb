{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import IPython.display\n",
    "\n",
    "# Basic Imports\n",
    "import gzip\n",
    "import cPickle as pickle\n",
    "import pandas as pd\n",
    "import random\n",
    "import seaborn\n",
    "# import librosa\n",
    "import sklearn\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data_utils\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 44M\r\n",
      "drwxr-xr-x   32 Junior 1.0K Nov  4 17:56 ./\r\n",
      "drwxr-xr-x+ 118 Junior 3.7K Dec 16 12:36 ../\r\n",
      "-rw-r--r--    1 Junior 6.1K Jun  1  2017 .DS_Store\r\n",
      "drwxr-xr-x   15 Junior  480 Dec 16 12:36 .git/\r\n",
      "drwxr-xr-x   11 Junior  352 Nov  3 09:47 .ipynb_checkpoints/\r\n",
      "-rw-r--r--    1 Junior 481K Oct 11 08:35 Audio VAE Mag & Phase.ipynb\r\n",
      "-rw-r--r--    1 Junior 2.8M Sep 17 18:39 DCT Tricks.ipynb\r\n",
      "-rw-r--r--    1 Junior 186K Oct 12 12:43 GAN Tutorial.ipynb\r\n",
      "-rw-r--r--    1 Junior   57 May  2  2017 README.md\r\n",
      "-rw-r--r--    1 Junior 447K Nov  2 13:04 RecoNet Model2.ipynb\r\n",
      "-rw-r--r--    1 Junior 445K Nov  3 09:47 RecoNet.ipynb\r\n",
      "-rw-r--r--    1 Junior 5.8K Oct 22 21:50 RecoNet.py\r\n",
      "-rw-r--r--    1 Junior 157K Oct 24 22:43 Robustness of DNN Activations.ipynb\r\n",
      "-rw-r--r--    1 Junior  21K Oct 22 21:46 Seq2Seq Tutorial.ipynb\r\n",
      "-rw-r--r--    1 Junior 1.2M Oct 12 12:36 Spoken Digits VAE.ipynb\r\n",
      "-rw-r--r--    1 Junior  19M May  3  2017 SpokenDigitDB.pkl.gz\r\n",
      "-rw-r--r--    1 Junior  35K May 16  2017 VAE Audio 1.png\r\n",
      "-rw-r--r--    1 Junior  52K May 16  2017 VAE Audio 2.png\r\n",
      "-rw-r--r--    1 Junior  52K May 16  2017 VAE Audio 3.png\r\n",
      "-rw-r--r--    1 Junior  49K May 16  2017 VAE Audio 4.png\r\n",
      "-rw-r--r--    1 Junior  740 Nov  4 17:56 attention.py\r\n",
      "-rw-r--r--    1 Junior  960 Oct 16 13:23 discovery_submit.sh\r\n",
      "-rw-r--r--    1 Junior 9.6M Oct 17 17:18 fra.txt\r\n",
      "-rw-r--r--    1 Junior 1.7M Sep 27  2016 handel.wav\r\n",
      "-rw-r--r--    1 Junior 621K May 11  2017 keras_mnist.ipynb\r\n",
      "drwxr-xr-x   17 Junior  544 Jun  1  2017 logs/\r\n",
      "-rw-r--r--    1 Junior 2.9M Nov  2 13:04 reconet.h5\r\n",
      "-rw-r--r--    1 Junior 4.2M Oct 17 17:18 s2s.h5\r\n",
      "-rw-r--r--    1 Junior  92K Jun  1  2017 sample_figure.png\r\n",
      "-rw-r--r--    1 Junior  11K Jun  1  2017 sample_original.wav\r\n",
      "-rw-r--r--    1 Junior  11K Jun  1  2017 sample_reconst.wav\r\n",
      "-rw-r--r--    1 Junior 7.0K May 12  2017 variational_autoencoder_deconv.py\r\n"
     ]
    }
   ],
   "source": [
    "ls -lah ../vae/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File loaded as ../vae/SpokenDigitDB.pkl.gz\n"
     ]
    }
   ],
   "source": [
    "# Loaded Spoken Digits Dataset\n",
    "dbfile ='../vae/SpokenDigitDB.pkl.gz'\n",
    "with gzip.open(dbfile, 'rb') as ifile:\n",
    "    df = pd.read_pickle(ifile)\n",
    "    print('File loaded as '+ dbfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[84]\n"
     ]
    }
   ],
   "source": [
    "# Padding & Truncating\n",
    "maxlen = 84\n",
    "pad    = lambda a, n: a[:,0: n] if a.shape[1] > n else np.hstack((a, np.min(a[:])*np.ones([a.shape[0],n - a.shape[1]])))\n",
    "df.Magnitude = df.Magnitude.apply(pad,args=(maxlen,))  # MaxLen Truncation Voodoo :D\n",
    "print(np.unique([np.shape(x)[1] for x in df.Magnitude]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio controls=\"controls\" >\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Sample\n",
    "sr = 8000  \n",
    "j  = random.randrange(len(df))\n",
    "IPython.display.Audio(data=df.Wave[j], rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Feature size: (335, 64, 84)\n",
      "Training Target  size: (335, 10)\n",
      "\n",
      "Testing  Feature size: (166, 64, 84)\n",
      "Testing  Target  size: (166, 10)\n"
     ]
    }
   ],
   "source": [
    "# Prepare Data\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Train Scaler\n",
    "x_data = df.Magnitude.values\n",
    "normsc = np.hstack(x_data)\n",
    "scaler = MinMaxScaler().fit(normsc.T)\n",
    "\n",
    "# Transform Data using Scaler\n",
    "x_data = [scaler.transform(arr.T).T for arr in df.Magnitude.values]\n",
    "x_data = np.dstack(x_data).transpose(2,0,1)\n",
    "\n",
    "# Add Singleton\n",
    "# x_data = x_data[...,None]         # Add singleton class\n",
    "# y_data = df.Class.cat.codes.values\n",
    "y_data = pd.get_dummies(df.Class).values\n",
    "# y_data = y_data.astype('int')\n",
    "\n",
    "# Shuffle & Split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x_data,y_data,\n",
    "                              test_size=0.33, random_state=32)\n",
    "\n",
    "# Print Dimensions\n",
    "print 'Training Feature size:', x_train.shape\n",
    "print 'Training Target  size:', y_train.shape\n",
    "print ''\n",
    "print 'Testing  Feature size:', x_test.shape\n",
    "print 'Testing  Target  size:', y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84, 501, 64)"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data.transpose(1,2,0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Torch DataLoader\n",
    "feats = torch.from_numpy(x_train)\n",
    "targs = torch.from_numpy(y_train)\n",
    "\n",
    "dtrain = data_utils.TensorDataset(features, targets)\n",
    "loader = data_utils.DataLoader(train,batch_size=10,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Recurrent Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Input Dimensions\n",
    "_,fbins,steps = x_data.shape\n",
    "nclass = len(np.unique(y_data))\n",
    "\n",
    "# Parameters\n",
    "L1 = 32\n",
    "L2 = 20\n",
    "L3 = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): GRU(64, 32)\n",
       "  (1): GRU(32, 20)\n",
       "  (2): GRU(20, 16)\n",
       "  (3): Linear(in_features=16, out_features=2)\n",
       ")"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model\n",
    "model = torch.nn.Sequential(\n",
    "    nn.GRU(fbins,L1,1),\n",
    "    nn.GRU(L1,L2,1),\n",
    "    nn.GRU(L2,L3,1),\n",
    "    nn.Linear(L3,nclass)\n",
    ")\n",
    "\n",
    "model.double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using GRU layers, Without Time Loop\n",
    "gru1 = nn.GRU(fbins,L1).double()\n",
    "gru2 = nn.GRU(L1,L2).double()\n",
    "fc3  = nn.Linear(L2,L3).double()\n",
    "fc4  = nn.Linear(L3,nclass).double()\n",
    "\n",
    "\n",
    "for i, data in enumerate(loader):\n",
    "    outputs = []\n",
    "    x,y = data\n",
    "    x,y = Variable(x.permute(2,0,1)),Variable(y)\n",
    "    \n",
    "    h1 = Variable(torch.zeros(1,x.size(1), L1)).double()\n",
    "    h2 = Variable(torch.zeros(1,x.size(1), L2)).double()\n",
    "\n",
    "    o1,h1 = gru1(x,h1)     # return output sequence o1\n",
    "    o2,h2 = gru2(o1,h2)    # return output sequence o1\n",
    "    lin  = F.relu(fc3(h2)) # use last state\n",
    "    out  = F.softmax(fc4(lin),dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Cell, With Time Loop \n",
    "gru1 = nn.GRUCell(fbins,L1).double()\n",
    "gru2 = nn.GRUCell(L1,L2).double()\n",
    "fc3  = nn.Linear(L2,L3).double()\n",
    "fc4  = nn.Linear(L3,nclass).double()\n",
    "\n",
    "for i, data in enumerate(loader):\n",
    "    outputs = []\n",
    "    x,y = data\n",
    "    x,y = Variable(x.permute(2,0,1)),Variable(y)\n",
    "    \n",
    "    ht1 = Variable(torch.zeros(x.size(1), L1)).double()\n",
    "    ht2 = Variable(torch.zeros(x.size(1), L2)).double()\n",
    "    \n",
    "    for xt1 in x:\n",
    "        ht1 = gru1(xt1,ht1)\n",
    "        ht2 = gru2(ht1,ht2)\n",
    "        ot3 = F.relu(fc3(ht2))\n",
    "        out = F.softmax(fc4(ot3),dim=-1)\n",
    "        outputs += [out]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Sequence(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Sequence, self).__init__() \n",
    "        self.gru1 = nn.GRU(fbins,L1)\n",
    "        self.gru2 = nn.GRU(L1,L2)\n",
    "        self.fc3  = nn.Linear(L3,nclass)\n",
    "        \n",
    "        \n",
    "    def forward(self,inputs):\n",
    "        for i in inputs:\n",
    "            inp = i.view(1,1,-1)\n",
    "            h1  = self.gru1(inp,h1)\n",
    "            h2  = self.gru2(h1,h2)\n",
    "            out = self.fc3(h2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loss and Optimizer\n",
    "lr = 1e-4\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, m1: [64 x 84], m2: [64 x 96] at /Users/soumith/minicondabuild3/conda-bld/pytorch_1512379211386/work/torch/lib/TH/generic/THTensorMath.c:1416",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-123-4a7d71abc6a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mout\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m           \u001b[0;31m# Forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# Compute Loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m           \u001b[0;31m# Backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Junior/anaconda2/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Junior/anaconda2/lib/python2.7/site-packages/torch/nn/modules/container.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Junior/anaconda2/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Junior/anaconda2/lib/python2.7/site-packages/torch/nn/modules/rnn.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mflat_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         )\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_packed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Junior/anaconda2/lib/python2.7/site-packages/torch/nn/_functions/rnn.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, *fargs, **fkwargs)\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhack_onnx_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Junior/anaconda2/lib/python2.7/site-packages/torch/nn/_functions/rnn.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, weight, hidden)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mnexth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_first\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Junior/anaconda2/lib/python2.7/site-packages/torch/nn/_functions/rnn.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, hidden, weight)\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_directions\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m                 \u001b[0mhy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m                 \u001b[0mnext_hidden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0mall_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Junior/anaconda2/lib/python2.7/site-packages/torch/nn/_functions/rnn.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, hidden, weight)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreverse\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m             \u001b[0;31m# hack to handle LSTM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Junior/anaconda2/lib/python2.7/site-packages/torch/nn/_functions/rnn.pyc\u001b[0m in \u001b[0;36mGRUCell\u001b[0;34m(input, hidden, w_ih, w_hh, b_ih, b_hh)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mb_ih\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_ih\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_hh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0mgi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_ih\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_ih\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0mgh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_hh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_hh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mi_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Junior/anaconda2/lib/python2.7/site-packages/torch/nn/functional.pyc\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m    833\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: size mismatch, m1: [64 x 84], m2: [64 x 96] at /Users/soumith/minicondabuild3/conda-bld/pytorch_1512379211386/work/torch/lib/TH/generic/THTensorMath.c:1416"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "    rloss = 0.0    # running loss\n",
    "    for i, data in enumerate(loader):\n",
    "        x, y = data\n",
    "        x, y = Variable(x), Variable(y)  # Make variable\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        out  = model(x)           # Forward\n",
    "        loss = criterion(out,y)   # Compute Loss\n",
    "        loss.backward()           # Backward\n",
    "        optimizer.step()          # Optimize\n",
    "        \n",
    "        # print statistics\n",
    "        rloss += loss.data[0]\n",
    "        if i % 10 == 0:           # Print every 10 batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, rloss / 10))\n",
    "            rloss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
